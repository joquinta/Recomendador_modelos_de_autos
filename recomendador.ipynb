{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c7707f-050a-4ab0-a864-467f7e52a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install streamlit openai llama-index PyPDF2 python-docx pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca1c90e-f14b-46a0-bce9-6d446385c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import openai\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "\n",
    "st.set_page_config(page_title=\"Pregunta lo que quieras de los modelos Hyundai\", page_icon='ðŸš™', layout=\"centered\", initial_sidebar_state=\"auto\", menu_items=None)\n",
    "openai.api_key = st.secrets.openai_key\n",
    "st.title(\"Pregunta lo que quieras de los modelos Hyundai ðŸ’¬ðŸš™\")\n",
    "st.info(\"No es una aplicaciÃ³n oficial, se basa en las fichas pÃºblicas de cada auto\", icon=\"ðŸ“ƒ\")\n",
    "\n",
    "if \"messages\" not in st.session_state.keys():  # Initialize the chat messages history\n",
    "    st.session_state.messages = [\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Hola, conozco todos los modelos nuevos de Hyundai, puedes preguntarme sobre versiones, especificaciones y precios\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "@st.cache_resource(show_spinner=False)\n",
    "def load_data():\n",
    "    reader = SimpleDirectoryReader(input_dir=\"./data\", recursive=True)\n",
    "    docs = reader.load_data()\n",
    "    Settings.llm = OpenAI(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0.2,\n",
    "        system_prompt=\"\"\"Eres un vendedor de autos Hyundai, solo conoces esa marca.\n",
    "        Tienes un base de conocimientos de los diferentes modelos, versiones y precios.\n",
    "        Debes responder las preguntas de los clientes con un leguaje cercano y tÃ©cnico si la informaciÃ³n que piden es tÃ©cnica.\"\"\",\n",
    "    )\n",
    "    index = VectorStoreIndex.from_documents(docs)\n",
    "    return index\n",
    "\n",
    "\n",
    "index = load_data()\n",
    "\n",
    "if \"chat_engine\" not in st.session_state.keys():  # Initialize the chat engine\n",
    "    st.session_state.chat_engine = index.as_chat_engine(\n",
    "        chat_mode=\"condense_question\", verbose=True, streaming=True\n",
    "    )\n",
    "\n",
    "if prompt := st.chat_input(\n",
    "    \"Comienza aquÃ­\"\n",
    "):  # Prompt for user input and save to chat history\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "for message in st.session_state.messages:  # Write message history to UI\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.write(message[\"content\"])\n",
    "\n",
    "# If last message is not from assistant, generate a new response\n",
    "if st.session_state.messages[-1][\"role\"] != \"assistant\":\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        response_stream = st.session_state.chat_engine.stream_chat(prompt)\n",
    "        st.write_stream(response_stream.response_gen)\n",
    "        message = {\"role\": \"assistant\", \"content\": response_stream.response}\n",
    "        # Add response to message history\n",
    "        st.session_state.messages.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc74437-cb75-422c-8076-55fa35ec9bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f622ac2a-e68b-46d9-8a78-14446471c577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e55b48-35e0-474e-892f-acb31332580c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f18d2bd-ac96-428e-b32b-33a0b95d8bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
