# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GCvSnhWFGJTMYnl8M_VKQ3w8znTKQmb2
"""

import streamlit as st
import openai
from llama_index.llms.openai import OpenAI
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings

st.set_page_config(page_title="Pregunta lo que quieras de los modelos Hyundai", page_icon='ðŸš™', layout="centered", initial_sidebar_state="auto", menu_items=None)

#openai.api_key = st.secrets.openai_key
try:
    openai.api_key = st.secrets["openai_key"]
except Exception as e:
    st.error("Error accediendo a la clave de API. Verifica secrets.toml")
    st.write(f"Error: {e}")


st.title("Pregunta lo que quieras de los modelos Hyundai ðŸ’¬ðŸš™")
st.info("No es una aplicaciÃ³n oficial, se basa en las fichas pÃºblicas de cada auto", icon="ðŸ“ƒ")

if "messages" not in st.session_state.keys():  # Initialize the chat messages history
    st.session_state.messages = [
        {
            "role": "assistant",
            "content": "Hola, conozco todos los modelos nuevos de Hyundai, puedes preguntarme sobre versiones, especificaciones y precios",
        }
    ]

@st.cache_resource(show_spinner=False)
def load_data():
    reader = SimpleDirectoryReader(input_dir="./data", recursive=True)
    docs = reader.load_data()
    Settings.llm = OpenAI(
        model="gpt-3.5-turbo",
        temperature=0.2,
        system_prompt="""Eres un vendedor de autos Hyundai, solo conoces esa marca.
        Tienes un base de conocimientos de los diferentes modelos, versiones y precios.
        Debes responder las preguntas de los clientes con un leguaje cercano y tÃ©cnico si la informaciÃ³n que piden es tÃ©cnica.""",
    )
    index = VectorStoreIndex.from_documents(docs)
    return index


index = load_data()

if "chat_engine" not in st.session_state.keys():  # Initialize the chat engine
    st.session_state.chat_engine = index.as_chat_engine(
        chat_mode="condense_question", verbose=True, streaming=True
    )

if prompt := st.chat_input(
    "Comienza aquÃ­"
):  # Prompt for user input and save to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})

for message in st.session_state.messages:  # Write message history to UI
    with st.chat_message(message["role"]):
        st.write(message["content"])

# If last message is not from assistant, generate a new response
if st.session_state.messages[-1]["role"] != "assistant":
    with st.chat_message("assistant"):
        response_stream = st.session_state.chat_engine.stream_chat(prompt)
        st.write_stream(response_stream.response_gen)
        message = {"role": "assistant", "content": response_stream.response}
        # Add response to message history
        st.session_state.messages.append(message)
